{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Build first model(s) for selected time-series data, improved after feedback\n",
    "# \n",
    "# Version history (only major changes):\n",
    "# 2023-10-01: (v 014) Added secondary features\n",
    "# 2023-10-01: (v 012) After-feedback improvements\n",
    "# 2023-09-25: (v 010) Initial creation from template v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "McUNYSRES3BJ",
   "metadata": {
    "id": "McUNYSRES3BJ"
   },
   "source": [
    "# Part 1: System checks, imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e390d4",
   "metadata": {},
   "source": [
    "## Jupyter-related magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f66274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09649e2e",
   "metadata": {},
   "source": [
    "## System info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hGqZ4q0xTZzk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1674012234839,
     "user": {
      "displayName": "AnT",
      "userId": "07342426211356883844"
     },
     "user_tz": -180
    },
    "id": "hGqZ4q0xTZzk",
    "outputId": "35f3e5e1-8703-438f-a09d-f6237eb0fcb6"
   },
   "outputs": [],
   "source": [
    "# Get basic info about current system\n",
    "!nvidia-smi\n",
    "!hostname\n",
    "!uname -a\n",
    "!df -kh /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c332f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674012234840,
     "user": {
      "displayName": "AnT",
      "userId": "07342426211356883844"
     },
     "user_tz": -180
    },
    "id": "mPQv8mUdTfBI",
    "outputId": "851de211-3887-4b37-a036-bd13cd9eaec9"
   },
   "outputs": [],
   "source": [
    "# Check location and version of python\n",
    "!which python\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump version of important packages - TODO\n",
    "!python -m pip list | grep -E -i \"catb|scikit|nump|pand\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fd761d",
   "metadata": {},
   "source": [
    "## Set main dir, check Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c57b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autodetect Google Colab\n",
    "TO_USE_COLAB = None\n",
    "try:\n",
    "    PATH_MOUNT = \"/content/drive\"\n",
    "    from google.colab import drive\n",
    "    drive.mount(PATH_MOUNT)\n",
    "    TO_USE_COLAB = True\n",
    "except:\n",
    "    TO_USE_COLAB = False\n",
    "    \n",
    "print(f\"{TO_USE_COLAB=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d44396",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set main directory (root for all other paths)\n",
    "import os\n",
    "if TO_USE_COLAB:\n",
    "    PATH_MAIN_DIR = f\"{PATH_MOUNT}/MyDrive/<path-to-project TODO>\"\n",
    "else:\n",
    "    PATH_MAIN_DIR = os.path.abspath(\".\")\n",
    "assert os.path.isdir(PATH_MAIN_DIR)\n",
    "\n",
    "print(f\"Successfully checked: {PATH_MAIN_DIR=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d9c97",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606d3876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local imports\n",
    "#sys.path.append(os.path.join(PATH_MAIN_DIR, '../src'))\n",
    "\n",
    "# TODO\n",
    "# import st_utils as stu\n",
    "# import st_data_handlers as stdh\n",
    "#import df_utils as dfu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf92fb",
   "metadata": {},
   "source": [
    "# Part 2: Settings and switches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50b7e3",
   "metadata": {},
   "source": [
    "## Settings: data files, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b70c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "print(f\"{PATH_MAIN_DIR=}\")  # Already set and checked above\n",
    "\n",
    "DIR_DATA_SRC = os.path.join(PATH_MAIN_DIR, r'../_data/')\n",
    "assert os.path.isdir(DIR_DATA_SRC)\n",
    "print(f\"Successfully checked: {DIR_DATA_SRC=}\")\n",
    "\n",
    "FNAME = os.path.join(DIR_DATA_SRC, '__2023-09-25T155258_transformed_data.csv')\n",
    "assert os.path.isfile(FNAME)\n",
    "print(f\"Successfully checked: {FNAME=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef224b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column names for original domain (non-percentage)\n",
    "COL__ORIG__MAIN_CC = \"PALUM\"  # Main time-series column name (Commodity Code)\n",
    "COLS__ORIG__OTHER_CC = [\"PCOAL\", ]  # Other feature column names (Commodity Code, etc.)\n",
    "COLS__ORIG__ALL_GOOD = [COL__ORIG__MAIN_CC] + COLS__ORIG__OTHER_CC\n",
    "\n",
    "# Column names for percentage domain\n",
    "SUFFIX__PCT = \"_pct\"  # Suffix for columns with percentage change values\n",
    "COL__PCT__MAIN_CC = COL__ORIG__MAIN_CC + SUFFIX__PCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Columns in original domain: {COLS__ORIG__ALL_GOOD}, main column: '{COL__ORIG__MAIN_CC}'\")\n",
    "print(f\"Main column in percentage domain: '{COL__PCT__MAIN_CC}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddfd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of sliding window for test set\n",
    "TEST_WINDOW_SIZE = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b664d",
   "metadata": {},
   "source": [
    "## Settings: RANDOM_SEED, switchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ee625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block contains \"active\" settings that contol notebook execution.\n",
    "\n",
    "# Initial random state, to be used in init_seeds, etc.\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "\n",
    "# Settings for \"fast-check\" mode\n",
    "# If switched on, the notebook is supposed to run very fast (for example, <1 minute) to reveal obvious bugs.\n",
    "#IS_FAST_CHECK = True\n",
    "IS_FAST_CHECK = False\n",
    "\n",
    "# For IS_FAST_CHECK mode: randomly drop most rows (without shuffling). Different train/test sizes are vital for debugging.\n",
    "# TODO-case1: multiple files\n",
    "# N_ROWS_IN_FAST_MODE_FOR_TRAIN_TEST = (1001, 999)\n",
    "# TODO-case2: single file\n",
    "# N_ROWS_IN_FAST_MODE = 1000\n",
    "\n",
    "\n",
    "# Section switchers\n",
    "DO_XXX = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8a8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize major launch details in one string (examples: seed, data details, switchers, etc.)\n",
    "\n",
    "LAUNCH_TAG = f\"FC={int(IS_FAST_CHECK)};seed={RANDOM_SEED};XXX={int(DO_XXX)};test_window={TEST_WINDOW_SIZE}\"\n",
    "\n",
    "print(f\"{LAUNCH_TAG=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4fd769",
   "metadata": {},
   "source": [
    "# Part 3: Function definitions, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54173223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part should contain only function definitions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d8966",
   "metadata": {},
   "source": [
    "## Defs: Init seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2293049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def init_seeds(seed=42):\n",
    "    # Python and CPU-related entropy  \n",
    "    random.seed(seed)      \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.use_deterministic_algorithms(True)   # Raises a CUBLAS error on some cases\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Does not help for the error above\n",
    "\n",
    "    # GPU-related entropy\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.benchmark = False  # See \n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9376265",
   "metadata": {},
   "source": [
    "## Everything is ready - go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initialize modules with {RANDOM_SEED=}\")\n",
    "init_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the launch timer\n",
    "print(f\"{LAUNCH_TAG=}\")\n",
    "glob__start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e065d",
   "metadata": {},
   "source": [
    "# Part 4: Data load and domain transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a3f8f",
   "metadata": {},
   "source": [
    "## Data: Do load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bdb48e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple files case\n",
    "# df_train_X = pd.read_csv(FNAME_TRAIN_X, index_col=False)\n",
    "# df_train_y = pd.read_csv(FNAME_TRAIN_Y, index_col=False)\n",
    "# df_test_X = pd.read_csv(FNAME_TEST_X, index_col=False)\n",
    "# df_test_y = pd.read_csv(FNAME_TEST_Y, index_col=False)\n",
    "# print(df_train_X.shape, df_train_y.shape, df_test_X.shape, df_test_y.shape)\n",
    "\n",
    "# if IS_FAST_CHECK:\n",
    "#     dfu.drop_some_rows_inplace(df_train_X, df_train_y, n_final_rows=N_ROWS_IN_FAST_MODE_FOR_TRAIN_TEST[0], seed=RANDOM_SEED)\n",
    "#     dfu.drop_some_rows_inplace(df_test_X, df_test_y, n_final_rows=N_ROWS_IN_FAST_MODE_FOR_TRAIN_TEST[1], seed=RANDOM_SEED)\n",
    "    \n",
    "# Single files case\n",
    "df_src = pd.read_csv(FNAME, index_col=0)\n",
    "print(df_src.shape)\n",
    "\n",
    "# if IS_FAST_CHECK:\n",
    "#     dfu.drop_some_rows_inplace(df_main, n_final_rows=N_ROWS_IN_FAST_MODE, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b7d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave only required columns\n",
    "df = df_src[COLS__ORIG__ALL_GOOD].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3287",
   "metadata": {},
   "source": [
    "## Data: plot and transformation from original domain to percentage domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c96bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[COL__ORIG__MAIN_CC].plot(title=COL__ORIG__MAIN_CC, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff727b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate columns in percentage domain\n",
    "cols_orig = df.columns.to_list()\n",
    "cols_pct_lag0 = []\n",
    "for c in cols_orig:\n",
    "    new_name = f\"{c}{SUFFIX__PCT}\"\n",
    "    assert new_name not in df.columns\n",
    "    df[new_name] = df[c].pct_change()\n",
    "    cols_pct_lag0.append(new_name)\n",
    "    \n",
    "cols_pct_lag0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629794ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot main (target) column in percentage domain\n",
    "df[COL__PCT__MAIN_CC].plot(title=COL__PCT__MAIN_CC, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cols_orig=}\")\n",
    "print(f\"{cols_pct_lag0=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1fa57",
   "metadata": {},
   "source": [
    "# Part 5: feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c813a21",
   "metadata": {},
   "source": [
    "## Add lag features for pct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608834e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lags = [1, 2, 3, 4, 5]  #, 6, 7, 8, 9, 10]\n",
    "\n",
    "cols_pct_lagged = []\n",
    "for col in cols_pct_lag0:\n",
    "    print(f\"{col=}\")\n",
    "    for lag in lags:\n",
    "        col_name = f\"{col}_(t-{lag})\"\n",
    "        df[col_name] = df[col].shift(lag)\n",
    "        cols_pct_lagged.append(col_name)\n",
    "\n",
    "df = df.copy()  # defragment dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all types of columns\n",
    "print(f\"{cols_orig=}\")\n",
    "print(f\"{cols_pct_lag0=}\")\n",
    "print(f\"{cols_pct_lagged=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature + target columns\n",
    "feature_cols = cols_pct_lagged  # We should use features ONLY with lag > 0\n",
    "target_col = COL__PCT__MAIN_CC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f131d9",
   "metadata": {},
   "source": [
    "## Drop NA rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected number of rows after NA removal\n",
    "old_len = len(df)\n",
    "expected_len = old_len - 1 - max(lags)\n",
    "\n",
    "# Do drop na and check\n",
    "df.dropna(axis='rows', inplace=True)\n",
    "assert len(df) == expected_len, f\"{len(df)=} vs {expected_len}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ce5f9",
   "metadata": {},
   "source": [
    "## Add tsfresh features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: rename columns to remove \"__\" (unsupported by TSFresh)\n",
    "import re\n",
    "def replace_underscore(s: str):\n",
    "    return re.sub('_+', '_', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh import extract_features\n",
    "\n",
    "def get_tsfresh_x_y(df_X: pd.DataFrame, df_y: pd.DataFrame, cols: list[str],\n",
    "                    window_size: int = 7 * 24  # 1 week\n",
    "                   ):\n",
    "\n",
    "    assert len(df_X) > window_size, \"Too small dataset, tricky exceptions are possible!\"\n",
    "\n",
    "    df_X2 = df_X[cols].copy()\n",
    "\n",
    "    # Rename columns to remove \"__\" (unsupported by TSFresh)\n",
    "    map = {}\n",
    "    for c in cols:\n",
    "        if \"__\" in c:\n",
    "            map[c] = replace_underscore(c)\n",
    "    print(f\"DBG: renaming map: {map}\")\n",
    "    df_X2.rename(map, axis=1, inplace=True)\n",
    "\n",
    "    # Generate fake \"id\" (required for TSFresh)\n",
    "    assert \"id\" not in df_X2.columns\n",
    "    df_X2[\"id\"] = 1  # Fake id\n",
    "\n",
    "    # Generate fake \"time\" (required for TSFresh)\n",
    "    assert \"time\" not in df_X2.columns\n",
    "    df_X2[\"time\"] = range(len(df_X2))\n",
    "\n",
    "    # Generate tsfresh features (rathe magical code)\n",
    "    df_rolled = roll_time_series(df_X2, column_id=\"id\", column_sort=\"time\", min_timeshift=window_size, max_timeshift=window_size)\n",
    "    df_features = extract_features(df_rolled, column_id=\"id\", column_sort=\"time\")\n",
    "\n",
    "    # Prepare labels that are aligned with the features\n",
    "    df_labels = df_y.shift(-window_size)[:-window_size]    \n",
    "    assert len(df_labels) == len(df_features)\n",
    "\n",
    "    return df_features, df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_tsf_features, df_tsf_labels = get_tsfresh_x_y(df, df[target_col], cols=feature_cols, window_size=7)\n",
    "print(df_tsf_features.shape, df_tsf_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut df to align with tsfresh rows\n",
    "print(f\"Before: {df.shape}\")\n",
    "\n",
    "df = df.iloc[-len(df_tsf_features):, :]\n",
    "\n",
    "print(f\"After: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append tsf_features to df\n",
    "print(f\"Before: {df.shape}\")\n",
    "\n",
    "assert set(df.columns) & set(df_tsf_features.columns) == set(), \"Column conflict detected!\"\n",
    "df = pd.concat([df, df_tsf_features.set_index(df.index)], axis=\"columns\")  # Note: ignore_index=True will NOT work here (!)\n",
    "\n",
    "feature_cols += df_tsf_features.columns.to_list()\n",
    "print(f\"After: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a5340",
   "metadata": {},
   "source": [
    "## Drop NA feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2734a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This NA removal may be skipped for some models, supporting NA values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74159c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before: {len(feature_cols)=}\")\n",
    "feature_cols = df[feature_cols].dropna(axis=\"columns\").columns.to_list()                 \n",
    "print(f\"After: {len(feature_cols)=}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc2db1",
   "metadata": {},
   "source": [
    "## Remove trivial columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4748a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Before: {len(feature_cols)=}\")\n",
    "for f in feature_cols.copy():\n",
    "    val_counts = df[f].value_counts()\n",
    "    if len(val_counts) == 1:\n",
    "        print(f\"Trivial feature removed:{f}\")\n",
    "        feature_cols.remove(f)\n",
    "print(f\"After: {len(feature_cols)=}\")                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no duplicates in features\n",
    "assert len(set(feature_cols)) == len(feature_cols), \"Duplicates detected!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17294e",
   "metadata": {},
   "source": [
    "# Do train-test cycles (sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897121f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Example of sliding window approach:\n",
    "# df=[0, 1, 2, 3, 4] (len=5), TEST_WINDOW_SIZE = 2\n",
    "# Expected train/test sets: \n",
    "#  1) [0, 1, 2], [3]\n",
    "#  2) [0, 1, 2, 3], [4]\n",
    "\n",
    "# Calculate possible values of test indices\n",
    "test_range = range(len(df) - TEST_WINDOW_SIZE, len(df))  # (5 - 2, 5) -> [3, 4]\n",
    "\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "for i, i_test in enumerate(tqdm(list(test_range))):\n",
    "    \n",
    "    # Split into train-test\n",
    "    train_data = df.iloc[0:i_test]\n",
    "    test_data = df.iloc[i_test:i_test+1]\n",
    "\n",
    "    #Separate features and target\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data[target_col]\n",
    "    idx_test = test_data.index\n",
    "    \n",
    "    # Initialize and fit a model\n",
    "    \n",
    "    # Model 1: trivial prediction (last value from train set)\n",
    "#     model = None\n",
    "#     y_pred = train_data[COL__PCT__MAIN_CC].iloc[-1:]\n",
    "    \n",
    "#     # Model 2: linear regression model\n",
    "#     model = LinearRegression()\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "#     # Model 3: RF\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Model 4: CB\n",
    "#     model = CatBoostRegressor(random_state=RANDOM_SEED, verbose=False)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Convert prediction to scalar (to be sure)\n",
    "    assert len(y_pred) == 1\n",
    "    y_pred = y_pred[0]\n",
    "    \n",
    "    # Convert prediction from pct-domain to original domain\n",
    "    prev_orig_value = train_data[COL__ORIG__MAIN_CC].iloc[-1:][0]  # Convert to scalar\n",
    "    y_pred_orig = prev_orig_value * (1 + float(y_pred))\n",
    "    y_true_orig = test_data[COL__ORIG__MAIN_CC].iloc[0]\n",
    "    \n",
    "    y_trues.append(y_true_orig)\n",
    "    y_preds.append(y_pred_orig)\n",
    "\n",
    "    # Calculate temp MAPE (for debug info)\n",
    "    #mae_cur = mean_absolute_error([y_true_orig], [y_pred_orig])\n",
    "    pred_err = y_pred_orig - y_true_orig\n",
    "    mape_cur = mean_absolute_percentage_error([y_true_orig], [y_pred_orig])\n",
    "    mape_avg = mean_absolute_percentage_error(y_trues, y_preds)\n",
    "    print(f\"{i=}, {idx_test=}, {pred_err=:.3f}, {mape_cur=:.3f}, {mape_avg=:.3f}\")\n",
    "    \n",
    "# Calculate the average MAPE for the whole test window\n",
    "mape = mean_absolute_percentage_error(y_trues, y_preds)\n",
    "print(f\"Average MAPE: {mape:.5f}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455bfdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VERSION 2 (fixed data leak from PCOAL lag0 feature)\n",
    "# Average MAPE: 0.05870 - trivial prediction (take last value)\n",
    "# Average MAPE: 0.05724 - LR\n",
    "# Average MAPE: 0.05115 - RF\n",
    "# Average MAPE: 0.05334 - CB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503ab50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f3455",
   "metadata": {},
   "source": [
    "# Plot model importance (WARN: for last model only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(model, 'feature_importances_'):\n",
    "    \n",
    "    feature_importance_tuples = [(k, v) for k, v in zip(model.feature_names_in_, model.feature_importances_)]\n",
    "    sorted_feature_importance_tuples = sorted(feature_importance_tuples, key=lambda x: x[1], reverse=True)\n",
    "    sorted_feature_names, sorted_importances = zip(*sorted_feature_importance_tuples)\n",
    "\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.bar(x=sorted_feature_names, height=sorted_importances)\n",
    "    plt.title(\"Feature imporatances\")\n",
    "else:\n",
    "    print(\"No feature importances found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd4580",
   "metadata": {},
   "source": [
    "# Plot results (for whole test period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw predictions and ground truth on a single chart\n",
    "plt.plot(y_preds, \"bo-\", label=\"Pred\")\n",
    "plt.plot(y_trues, \"gs--\", label=\"True\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw predictions vs ground truth\n",
    "plt.scatter(x=y_preds, y=y_trues)\n",
    "\n",
    "# Draw diagonal\n",
    "val_min = min(y_preds, y_trues)\n",
    "val_max = max(y_preds, y_trues)\n",
    "plt.plot([val_min, val_max], [val_min, val_max], linestyle='-', color='lightblue', label='Diagonal')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.gca().set_xlabel(\"Predictions\")\n",
    "plt.gca().set_ylabel(\"Ground truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea45e5f",
   "metadata": {},
   "source": [
    "# Finalize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Elapsed notebook seconds: {time.time() - glob__start_time:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd2377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "438.802px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
