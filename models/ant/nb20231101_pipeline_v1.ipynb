{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f887d249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Simple pipeline for time-series data transformation and modeling learning Build first model(s) for selected time-series data, improved after feedback\n",
    "# \n",
    "# Version history (only major changes):\n",
    "# \n",
    "# 2023-11-01: (v 1) Combination of drafts for data transformation + model launching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "McUNYSRES3BJ",
   "metadata": {
    "id": "McUNYSRES3BJ"
   },
   "source": [
    "# Part 1: System checks, imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e390d4",
   "metadata": {},
   "source": [
    "## Jupyter-related magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f66274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable auto-reload of imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09649e2e",
   "metadata": {},
   "source": [
    "## System info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hGqZ4q0xTZzk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 425,
     "status": "ok",
     "timestamp": 1674012234839,
     "user": {
      "displayName": "AnT",
      "userId": "07342426211356883844"
     },
     "user_tz": -180
    },
    "id": "hGqZ4q0xTZzk",
    "outputId": "35f3e5e1-8703-438f-a09d-f6237eb0fcb6"
   },
   "outputs": [],
   "source": [
    "# Get basic info about current system\n",
    "!nvidia-smi\n",
    "!hostname\n",
    "!uname -a\n",
    "!df -kh /tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c332f5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674012234840,
     "user": {
      "displayName": "AnT",
      "userId": "07342426211356883844"
     },
     "user_tz": -180
    },
    "id": "mPQv8mUdTfBI",
    "outputId": "851de211-3887-4b37-a036-bd13cd9eaec9"
   },
   "outputs": [],
   "source": [
    "# Check location and version of python\n",
    "!which python\n",
    "!python -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc15629b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump version of important packages\n",
    "!python -m pip list | grep -E -i \"catb|scikit|nump|pand\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347d9c97",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import torch  # Currently used only for seeding CUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbf92fb",
   "metadata": {},
   "source": [
    "# Part 2: Settings and switches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50b7e3",
   "metadata": {},
   "source": [
    "## Settings for data files, columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f56beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "FNAME_DATA_SRC = os.path.join(r'../../data/PCPS_06-08-2023 20-05-34-68_timeSeries.csv')\n",
    "assert os.path.isfile(FNAME_DATA_SRC), f\"{FNAME_DATA_SRC=}\"\n",
    "print(f\"Successfully checked: {FNAME_DATA_SRC=}\")\n",
    "\n",
    "FNAME_DATA_PREDICTION = r'pipeline_v1_out.csv'\n",
    "\n",
    "\n",
    "# Commodity Code to select (may be wider than actually used for modeling)\n",
    "COLS__INTERESTING_CC = [\n",
    "    \"PALUM\",    # Aluminum\n",
    "    \"PCOAL\",    # Coal index \n",
    "    \"PALLMETA\"  # All Metals Index    \n",
    "]\n",
    "\n",
    "# Unit Code to select\n",
    "UNIT_CODE = \"IX\"\n",
    "\n",
    "# Range of dates to select\n",
    "COL__BEGIN_TS_LABEL = \"1990M1\"\n",
    "COL__END_TS_LABEL = \"2023M5\"\n",
    "\n",
    "\n",
    "# Column names for original domain (non-percentage)\n",
    "COL__ORIG__MAIN_CC = \"PALUM\"  # Main time-series column name (Commodity Code)\n",
    "COLS__ORIG__OTHER_CC = [\"PCOAL\", ]  # Other feature column names (Commodity Code, etc.)\n",
    "COLS__ORIG__ALL_GOOD = [COL__ORIG__MAIN_CC] + COLS__ORIG__OTHER_CC\n",
    "\n",
    "# Column names for percentage domain\n",
    "SUFFIX__PCT = \"_pct\"  # Suffix for columns with percentage change values\n",
    "COL__PCT__MAIN_CC = COL__ORIG__MAIN_CC + SUFFIX__PCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Columns in original domain: {COLS__ORIG__ALL_GOOD}, main column: '{COL__ORIG__MAIN_CC}'\")\n",
    "print(f\"Main column in percentage domain: '{COL__PCT__MAIN_CC}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ddfd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of lags for feature generation\n",
    "FEATURE_LAGS = [1, 2, 3, 4, 5]  #, 6, 7, 8, 9, 10]\n",
    "\n",
    "# Size of sliding window for test set\n",
    "TEST_WINDOW_SIZE = 24\n",
    "\n",
    "# Size of window for TsFresh (feature generation library)\n",
    "TSFRESH_WINDOW_SIZE = 7  # 7 months"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58b664d",
   "metadata": {},
   "source": [
    "## Settings: RANDOM_SEED, switchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571ee625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block contains \"active\" settings that contol notebook execution.\n",
    "\n",
    "# Initial random state, to be used in init_seeds, etc.\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4fd769",
   "metadata": {},
   "source": [
    "# Part 3: Function definitions, start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54173223",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part should contain only function definitions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320d8966",
   "metadata": {},
   "source": [
    "## Defs: Init seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2293049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More info: https://pytorch.org/docs/stable/notes/randomness.html\n",
    "def init_seeds(seed=42):\n",
    "    # Python and CPU-related entropy  \n",
    "    random.seed(seed)      \n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    # torch.use_deterministic_algorithms(True)   # Raises a CUBLAS error on some cases\n",
    "    # os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Does not help for the error above\n",
    "\n",
    "    # GPU-related entropy\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) # gpu vars\n",
    "        torch.backends.cudnn.benchmark = False  # See \n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9376265",
   "metadata": {},
   "source": [
    "## Everything is ready - go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c329b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Initialize modules with {RANDOM_SEED=}\")\n",
    "init_seeds(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbfd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the launch timer\n",
    "glob__start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e065d",
   "metadata": {},
   "source": [
    "# Part 4: Data load and domain transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15a3f8f",
   "metadata": {},
   "source": [
    "## Data: Do load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da85e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_src = pd.read_csv(FNAME_DATA_SRC, index_col=False)\n",
    "print(df_src.shape)\n",
    "df_src"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a318fa24",
   "metadata": {},
   "source": [
    "## Transform data to row-level time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387695c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(COLS__INTERESTING_CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383a4cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp = df_src[(df_src[\"Commodity Code\"].isin(COLS__INTERESTING_CC)) & (df_src[\"Unit Code\"] == \"IX\")]\n",
    "assert len(df_tmp) == len(COLS__INTERESTING_CC)\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad7ca90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of feature columns (order may be different from ours)\n",
    "CC_LABELS = df_tmp[\"Commodity Code\"].to_list()\n",
    "CC_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fea380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare resulting dataframe (transposed)\n",
    "df_main = df_tmp.loc[:, COL__BEGIN_TS_LABEL:COL__END_TS_LABEL].T\n",
    "\n",
    "# Assign column names\n",
    "df_main.columns = CC_LABELS\n",
    "\n",
    "# Show the result\n",
    "df_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e9a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLS__ORIG__ALL_GOOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665b9eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leave only required columns\n",
    "df = df_main[COLS__ORIG__ALL_GOOD].copy()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a3287",
   "metadata": {},
   "source": [
    "## Data: plot and transformation from original domain to percentage domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c96bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[COL__ORIG__MAIN_CC].plot(title=COL__ORIG__MAIN_CC, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff727b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate columns in percentage domain\n",
    "cols_orig = df.columns.to_list()\n",
    "cols_pct_lag0 = []\n",
    "for c in cols_orig:\n",
    "    new_name = f\"{c}{SUFFIX__PCT}\"\n",
    "    assert new_name not in df.columns\n",
    "    df[new_name] = df[c].pct_change()\n",
    "    cols_pct_lag0.append(new_name)\n",
    "    \n",
    "cols_pct_lag0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629794ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot main (target) column in percentage domain\n",
    "df[COL__PCT__MAIN_CC].plot(title=COL__PCT__MAIN_CC, grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f52c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cols_orig=}\")\n",
    "print(f\"{cols_pct_lag0=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a1fa57",
   "metadata": {},
   "source": [
    "# Part 5: feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c813a21",
   "metadata": {},
   "source": [
    "## Add lag features for pct columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608834e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cols_pct_lagged = []\n",
    "for col in cols_pct_lag0:\n",
    "    print(f\"{col=}\")\n",
    "    for lag in FEATURE_LAGS:\n",
    "        col_name = f\"{col}_(t-{lag})\"\n",
    "        df[col_name] = df[col].shift(lag)\n",
    "        cols_pct_lagged.append(col_name)\n",
    "\n",
    "df = df.copy()  # defragment dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f53c701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all types of columns\n",
    "print(f\"{cols_orig=}\")\n",
    "print(f\"{cols_pct_lag0=}\")\n",
    "print(f\"{cols_pct_lagged=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature + target columns\n",
    "feature_cols = cols_pct_lagged  # We should use features ONLY with lag > 0\n",
    "target_col = COL__PCT__MAIN_CC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f131d9",
   "metadata": {},
   "source": [
    "## Drop NA rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcc3bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected number of rows after NA removal\n",
    "old_len = len(df)\n",
    "expected_len = old_len - 1 - max(FEATURE_LAGS)\n",
    "\n",
    "# Do drop na and check\n",
    "df.dropna(axis='rows', inplace=True)\n",
    "assert len(df) == expected_len, f\"{len(df)=} vs {expected_len}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d2de74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df  # Shape should change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d01ce5f9",
   "metadata": {},
   "source": [
    "## Add tsfresh features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901f087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: rename columns to remove \"__\" (unsupported by TSFresh)\n",
    "import re\n",
    "def replace_underscore(s: str):\n",
    "    return re.sub('_+', '_', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0dddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh.utilities.dataframe_functions import roll_time_series\n",
    "from tsfresh import extract_features\n",
    "\n",
    "def get_tsfresh_x_y(df_X: pd.DataFrame, df_y: pd.DataFrame, cols: list[str],\n",
    "                    window_size: int = 7 * 24  # 1 week for 1h dataset\n",
    "                   ):\n",
    "\n",
    "    assert len(df_X) > window_size, \"Too small dataset, tricky exceptions are possible!\"\n",
    "\n",
    "    df_X2 = df_X[cols].copy()\n",
    "\n",
    "    # Rename columns to remove \"__\" (unsupported by TSFresh)\n",
    "    map = {}\n",
    "    for c in cols:\n",
    "        if \"__\" in c:\n",
    "            map[c] = replace_underscore(c)\n",
    "    print(f\"DBG: renaming map: {map}\")\n",
    "    df_X2.rename(map, axis=1, inplace=True)\n",
    "\n",
    "    # Generate fake \"id\" (required for TSFresh)\n",
    "    assert \"id\" not in df_X2.columns\n",
    "    df_X2[\"id\"] = 1  # Fake id\n",
    "\n",
    "    # Generate fake \"time\" (required for TSFresh)\n",
    "    assert \"time\" not in df_X2.columns\n",
    "    df_X2[\"time\"] = range(len(df_X2))\n",
    "\n",
    "    # Generate tsfresh features (rathe magical code)\n",
    "    df_rolled = roll_time_series(df_X2, column_id=\"id\", column_sort=\"time\", min_timeshift=window_size, max_timeshift=window_size)\n",
    "    df_features = extract_features(df_rolled, column_id=\"id\", column_sort=\"time\")\n",
    "\n",
    "    # Prepare labels that are aligned with the features\n",
    "    df_labels = df_y.shift(-window_size)[:-window_size]    \n",
    "    assert len(df_labels) == len(df_features)\n",
    "\n",
    "    return df_features, df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4cd654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"{TSFRESH_WINDOW_SIZE=}\")\n",
    "df_tsf_features, df_tsf_labels = get_tsfresh_x_y(df, df[target_col], cols=feature_cols, window_size=TSFRESH_WINDOW_SIZE)\n",
    "print(df_tsf_features.shape, df_tsf_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6696208f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut df to align with tsfresh rows\n",
    "print(f\"Before: {df.shape}\")\n",
    "\n",
    "df = df.iloc[-len(df_tsf_features):, :]\n",
    "\n",
    "print(f\"After: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a3179e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append tsf_features to df\n",
    "print(f\"Before: {df.shape}\")\n",
    "\n",
    "assert set(df.columns) & set(df_tsf_features.columns) == set(), \"Column conflict detected!\"\n",
    "df = pd.concat([df, df_tsf_features.set_index(df.index)], axis=\"columns\")  # Note: ignore_index=True will NOT work here (!)\n",
    "\n",
    "feature_cols += df_tsf_features.columns.to_list()\n",
    "print(f\"After: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2a5340",
   "metadata": {},
   "source": [
    "## Drop NA feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2734a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This NA removal may be skipped for some models, supporting NA values in features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74159c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Before: {len(feature_cols)=}\")\n",
    "feature_cols = df[feature_cols].dropna(axis=\"columns\").columns.to_list()                 \n",
    "print(f\"After: {len(feature_cols)=}\")                 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fc2db1",
   "metadata": {},
   "source": [
    "## Remove trivial columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4748a08",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "print(f\"Before: {len(feature_cols)=}\")\n",
    "for f in feature_cols.copy():\n",
    "    val_counts = df[f].value_counts()\n",
    "    if len(val_counts) == 1:\n",
    "        print(f\"Trivial feature removed:{f}\")\n",
    "        feature_cols.remove(f)\n",
    "print(f\"After: {len(feature_cols)=}\")                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852983b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check there are no duplicates in features\n",
    "assert len(set(feature_cols)) == len(feature_cols), \"Duplicates detected!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a17294e",
   "metadata": {},
   "source": [
    "# Do train-test cycles (sliding window)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82d6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfc765",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{TEST_WINDOW_SIZE=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e897121f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Example of sliding window approach:\n",
    "# df=[0, 1, 2, 3, 4] (len=5), TEST_WINDOW_SIZE = 2\n",
    "# Expected train/test sets: \n",
    "#  1) [0, 1, 2], [3]\n",
    "#  2) [0, 1, 2, 3], [4]\n",
    "\n",
    "# Calculate possible values of test indices\n",
    "test_range = range(len(df) - TEST_WINDOW_SIZE, len(df))  # (5 - 2, 5) -> [3, 4]\n",
    "\n",
    "y_trues = []\n",
    "y_preds = []\n",
    "date_preds = []  # Dates for predictions (like \"2023M1\")\n",
    "for i, i_test in enumerate(tqdm(list(test_range))):\n",
    " \n",
    "    # Split into train-test\n",
    "    train_data = df.iloc[0:i_test]\n",
    "    test_data = df.iloc[i_test:i_test+1]\n",
    "\n",
    "    #Separate features and target\n",
    "    X_train = train_data[feature_cols]\n",
    "    y_train = train_data[target_col]\n",
    "\n",
    "    X_test = test_data[feature_cols]\n",
    "    y_test = test_data[target_col]\n",
    "    assert len(test_data.index) == 1\n",
    "    date_test = test_data.index[0]\n",
    "    \n",
    "    # Initialize and fit a model\n",
    "    \n",
    "    # Model 1: trivial prediction (last value from train set)\n",
    "    model = None\n",
    "    y_pred = train_data[COL__PCT__MAIN_CC].iloc[-1:]  # Ex: change between 2021M5/2021M4 \n",
    "    \n",
    "    # Model 2: linear regression model\n",
    "    # model = LinearRegression()\n",
    "    # model.fit(X_train, y_train)\n",
    "    # y_pred = model.predict(X_test)\n",
    "    \n",
    "# #     # Model 3: RF\n",
    "#     model = RandomForestRegressor(n_estimators=100, random_state=RANDOM_SEED)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "\n",
    "    # Model 4: CB\n",
    "#     model = CatBoostRegressor(random_state=RANDOM_SEED, verbose=False)\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Convert prediction to scalar (to be sure)\n",
    "    assert len(y_pred) == 1\n",
    "    y_pred = y_pred[0]\n",
    "    \n",
    "    # Convert prediction from pct-domain to original domain\n",
    "    prev_prev_orig_value = train_data[COL__ORIG__MAIN_CC].iloc[-2:][0]  # Convert to scalar. Ex: 144.58 from 2021M4\n",
    "    y_pred_orig = prev_prev_orig_value * (1 + float(y_pred))  # Ex: 144.58 * (1+0.049748) = 151.77\n",
    "    y_true_orig = test_data[COL__ORIG__MAIN_CC].iloc[0]\n",
    "    \n",
    "    y_trues.append(y_true_orig)\n",
    "    y_preds.append(y_pred_orig)\n",
    "    date_preds.append(date_test)\n",
    "\n",
    "    # Calculate temp MAPE (for debug info)\n",
    "    #mae_cur = mean_absolute_error([y_true_orig], [y_pred_orig])\n",
    "    pred_err = y_pred_orig - y_true_orig\n",
    "    mape_cur = mean_absolute_percentage_error([y_true_orig], [y_pred_orig])\n",
    "    mape_avg = mean_absolute_percentage_error(y_trues, y_preds)\n",
    "    print(f\"{i=}, {date_test=}, {pred_err=:.3f}, {mape_cur=:.3f}, {mape_avg=:.3f}\")\n",
    "    \n",
    "# Calculate the average MAPE for the whole test window\n",
    "mape = mean_absolute_percentage_error(y_trues, y_preds)\n",
    "print(f\"Average MAPE: {mape:.5f}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699f3455",
   "metadata": {},
   "source": [
    "# Plot model importance (WARN: for last model only!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa7ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(model, 'feature_importances_'):\n",
    "    \n",
    "    feature_importance_tuples = [(k, v) for k, v in zip(model.feature_names_in_, model.feature_importances_)]\n",
    "    sorted_feature_importance_tuples = sorted(feature_importance_tuples, key=lambda x: x[1], reverse=True)\n",
    "    sorted_feature_names, sorted_importances = zip(*sorted_feature_importance_tuples)\n",
    "\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.bar(x=sorted_feature_names, height=sorted_importances)\n",
    "    plt.title(\"Feature imporatances\")\n",
    "else:\n",
    "    print(\"No feature importances found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bd4580",
   "metadata": {},
   "source": [
    "# Plot results (for whole test period)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed9e21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw predictions and ground truth on a single chart\n",
    "plt.plot(y_preds, \"bo-\", label=\"Pred\")\n",
    "plt.plot(y_trues, \"gs--\", label=\"True\")\n",
    "plt.legend()\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fef415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw predictions vs ground truth\n",
    "plt.scatter(x=y_preds, y=y_trues)\n",
    "\n",
    "# Draw diagonal\n",
    "val_min = min(y_preds, y_trues)\n",
    "val_max = max(y_preds, y_trues)\n",
    "plt.plot([val_min, val_max], [val_min, val_max], linestyle='-', color='lightblue', label='Diagonal')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.gca().set_xlabel(\"Predictions\")\n",
    "plt.gca().set_ylabel(\"Ground truth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c5fdff",
   "metadata": {},
   "source": [
    "# Dump output predictions to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa30203",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame({\"DateStr\": date_preds, \"Prediction\": y_preds})\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1cd76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{FNAME_DATA_PREDICTION=}\")\n",
    "df_results.to_csv(FNAME_DATA_PREDICTION)  # Note: if the file exists, it will be overwritten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea45e5f",
   "metadata": {},
   "source": [
    "# Finalize notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178c7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Elapsed notebook seconds: {time.time() - glob__start_time:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c03a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "438.797px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
